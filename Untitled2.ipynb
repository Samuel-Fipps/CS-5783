{
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "part2.1",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from sklearn import tree\nimport pandas as pd\nimport numpy as np\nfrom sklearn import preprocessing\nfrom sklearn import utils\nfrom sklearn.metrics import accuracy_score\n\ndf = pd.read_excel(\"Asssignment4_Data.xlsx\")\n#print(df.head)\n\n\ny = df.iloc[ :, 1:2]\n\n\ny_list = []\ncount = 0 \nfor i in y.iloc:\n    y_list.append(i[0])\n    count += 1\n\n#y = (y.to_string(index=False, header=False))\n\nx = df.iloc[ :, 2:]\n\nx_list = []\nbig = []\nfor i in range(2, 9):\n    x = df.iloc[ :, i:i+1]\n    x_list = []\n    for j in x.iloc:\n\n        x_list.append(j[0])\n    big.append(x_list)\n\n\nx = np.array(big)\ny = np.array(y_list)\n\nencodedlabels = []\nfor i in y:\n    encodedlabels.append(int(i))\n\ny = np.array(encodedlabels)\n#y = y.reshape(1, -1)\nx = x.swapaxes(0, 1)\n\ncounter = 0\n#for feat in x:\n\n#x = x.reshape(1, -1)\nmodel = tree.DecisionTreeClassifier()\n\n\nfor feat, y_train in zip(x,y):\n\n    #feat = feat.reshape(1, -1)\n    model = model.fit(feat,y_train)\n    output = model.predict(feat)\n    \n\n    count = 0\n    right = 0\n    wrong = 0\n\n    for out in output[0]:\n        if out == y[0][count]: right += 1\n        else: wrong += 1\n        count += 1\n\n    print(right / (right + wrong))\n    counter += 1\n",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "part2.2",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from sklearn import tree\nimport pandas as pd\nimport numpy as np\nfrom sklearn import preprocessing\nfrom sklearn import utils\nfrom sklearn.metrics import accuracy_score\n\ndf = pd.read_excel(\"Asssignment4_Data.xlsx\")\n#print(df.head)\n\n\ny = df.iloc[ :, 1:2]\n\n\ny_list = []\ncount = 0 \nfor i in y.iloc:\n    y_list.append(i[0])\n    count += 1\n\n#y = (y.to_string(index=False, header=False))\n\nx = df.iloc[ :, 2:]\n\nx_list = []\nbig = []\nfor i in range(2, 9):\n    x = df.iloc[ :, i:i+1]\n    x_list = []\n    for j in x.iloc:\n\n        x_list.append(j[0])\n    big.append(x_list)\n\n\nx = np.array(big)\ny = np.array(y_list)\n\nencodedlabels = []\nfor i in y:\n    encodedlabels.append(int(i))\n\ny = np.array(encodedlabels)\n#y = y.reshape(1, -1)\nx = x.swapaxes(0, 1)\n\ncounter = 0\n#for feat in x:\nfeat = x\nfeat = feat.reshape(1, -1)\nmodel = tree.DecisionTreeClassifier()\n\ny = y.reshape(1, -1)\nmodel = model.fit(feat,y)\noutput = model.predict(feat)\n\ncount = 0\nright = 0\nwrong = 0\n\nfor out in output[0]:\n    if out == y[0][count]: right += 1\n    else: wrong += 1\n    count += 1\n\nprint(right / (right + wrong))\ncounter += 1\n\n\n\n\n\n\n\n# testing stuff\n\n\ndf = pd.read_excel(\"test.xlsx\")\n#print(df.head)\n\ny = df.iloc[ :, 1:2]\n\ny_list = []\ncount = 0 \nfor i in y.iloc:\n    y_list.append(i[0])\n    count += 1\n\n#y = (y.to_string(index=False, header=False))\n\nx = df.iloc[ :, 2:]\n\nx_list = []\nbig = []\nfor i in range(2, 9):\n    x = df.iloc[ :, i:i+1]\n    x_list = []\n    for j in x.iloc:\n\n        x_list.append(j[0])\n    big.append(x_list)\n\n\nx = np.array(big)\ny = np.array(y_list)\n\nencodedlabels = []\nfor i in y:\n    encodedlabels.append(int(i))\n\ny = np.array(encodedlabels)\n#y = y.reshape(1, -1)\nx = x.swapaxes(0, 1)\n\ncounter = 0\n#for feat in x:\nfeat = x\nfeat = feat.reshape(1, -1)\n#model = tree.DecisionTreeClassifier()\n\ny = y.reshape(1, -1)\n#model = model.fit(feat,y)\noutput = model.predict(feat)\n\ncount = 0\nright = 0\nwrong = 0\n\nfor out in output[0]:\n    if out == y[0][count]: right += 1\n    else: wrong += 1\n    count += 1\n\nprint(right / (right + wrong))\ncounter += 1\n",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "part2.3",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from sklearn import tree\nimport pandas as pd\nimport numpy as np\n\ndf = pd.read_excel(\"Asssignment4_Data.xlsx\")\n#print(df.head)\n\n\ny = df.iloc[ :, 1:2]\n\n\ny_list = []\ncount = 0 \nfor i in y.iloc:\n    y_list.append(i[0])\n    count += 1\n\n#y = (y.to_string(index=False, header=False))\n\nx = df.iloc[ :, 2:]\n\nx_list = []\nbig = []\nfor i in range(2, 9):\n    x = df.iloc[ :, i:i+1]\n    x_list = []\n    for j in x.iloc:\n\n        x_list.append(j[0])\n    big.append(x_list)\n\n\nx = np.array(big)\ny = np.array(y_list)\n\nencodedlabels = []\nfor i in y:\n    encodedlabels.append(int(i))\n\ny = np.array(encodedlabels)\ny = y.reshape(1, -1)\n\nfor feat in x:\n    feat = feat.reshape(1, -1)\n    model = tree.DecisionTreeClassifier(max_depth=1)\n    model = model.fit(feat,y)\n    output = model.predict(feat)\n    \n    count = 0\n    right = 0\n    wrong = 0\n    for out in output[0]:\n        if out == y[0][count]: right += 1\n        else: wrong += 1\n        count += 1\n\n    #print(right / (right + wrong))\n\n\n\"\"\"\ntesting data\n\"\"\"\ndel df\ndf = pd.read_excel(\"test.xlsx\")\n#print(df.head)\n\n\ny = df.iloc[ :, 1:2]\n\n\ny_list = []\ncount = 0 \nfor i in y.iloc:\n    y_list.append(i[0])\n    count += 1\n\n#y = (y.to_string(index=False, header=False))\n\nx = df.iloc[ :, 2:]\n\nx_list = []\nbig = []\nfor i in range(2, 9):\n    x = df.iloc[ :, i:i+1]\n    x_list = []\n    for j in x.iloc:\n\n        x_list.append(j[0])\n    big.append(x_list)\n\n\nx = np.array(big)\ny = np.array(y_list)\n\nencodedlabels = []\nfor i in y:\n    encodedlabels.append(int(i))\n\ny = np.array(encodedlabels)\ny = y.reshape(1, -1)\n\nx = x.swapaxes(0, 1)\nfor feat in x:\n    feat = feat.reshape(1, -1)\n    #model = tree.DecisionTreeClassifier()\n    #model = model.fit(feat,y)\n    output = model.predict(feat)\n    \n    count = 0\n    right = 0\n\n    for out in output[0]:\n        if out == y[0][count]: \n            right += 1\n        else: \n            wrong += 1\n        count += 1\n\n    print(right / (right + wrong))\n",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "part3",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import pandas as pd\nimport numpy as np\nfrom sklearn.neighbors import KNeighborsClassifier\n\ndf = pd.read_excel(\"Asssignment4_Data.xlsx\")\ny = df.iloc[ :, 1:2]\n\ny_list = []\ncount = 0 \nfor i in y.iloc:\n    y_list.append(i[0])\n    count += 1\n\nx = df.iloc[ :, 2:]\nx_list = []\nbig = []\nfor i in range(2, 9):\n    x = df.iloc[ :, i:i+1]\n    x_list = []\n    for j in x.iloc:\n\n        x_list.append(j[0])\n    big.append(x_list)\n\n\nx = np.array(big)\ny = np.array(y_list)\n\nencodedlabels = []\nfor i in y:\n    encodedlabels.append(int(i))\n\ny = np.array(encodedlabels)\ny = y.reshape(1, -1)\n\nx = x.swapaxes(0, 1)\nfeat = x\n\nmodel = KNeighborsClassifier(n_neighbors=3)\nmodel = model.fit(feat,y)\noutput = model.predict(feat)\ncount = 0\nright = 0\nwrong = 0\nfor out in output[0]:\n    if out == y[0][count]: right += 1\n    else: wrong += 1\n    count += 1\nprint(right / (right + wrong))\n",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "Question 2:\n1.a. What is the accuracy on the training set?  100% on all feats\n1.b. What is the accuracy on the test set? 25% on all feats\n2. The shorter the tree the worst the values. Best depth was 5\n3. Because it makes the tree branch out differently causing different structure.\n4. \n",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    }
  ]
}